#!/usr/bin/env node
/**
 * å¹¶å‘å¤„ç† AI ä»»åŠ¡ - ç”¨äºä¸æ”¯æŒ Batch API çš„ API ä»£ç†
 *
 * è¿™ä¸ªè„šæœ¬å¹¶å‘è°ƒç”¨ APIï¼Œè€Œä¸æ˜¯ä½¿ç”¨ OpenAI Batch APIã€‚
 * é€‚ç”¨äº new-api/one-api ç±»å‹çš„ API ä¸­è½¬ç«™ã€‚
 *
 * ç‰¹æ€§ï¼š
 *   - å¯é…ç½®å¹¶å‘æ•°ï¼Œæé«˜å¤„ç†æ•ˆç‡
 *   - ç»“æœæŒ‰åŸå§‹é¡ºåºè¾“å‡ºï¼Œç¡®ä¿æŠ¥å‘Šç”Ÿæˆæ­£ç¡®
 *   - ä¸¤å±‚é‡è¯•æœºåˆ¶ï¼šå•è¯·æ±‚é‡è¯• + æ‰¹é‡å¤±è´¥é‡è¯•
 *
 * Env:
 *   OPENAI_BASE_URL       default: https://api.openai.com
 *   OPENAI_API_KEY        required
 *   OPENAI_MODEL          default: gpt-4o-mini
 *   AI_JSONL_PATH         default: ai/batch_all.jsonl
 *   AI_CONCURRENCY        default: 5 (å¹¶å‘æ•°)
 *   AI_DELAY_BETWEEN_MS   default: 200 (è¯·æ±‚é—´éš”æ¯«ç§’)
 *   AI_RETRY_ROUNDS       default: 2 (å¤±è´¥ä»»åŠ¡é‡è¯•è½®æ•°)
 *
 * Usage:
 *   node src/ai/process-events-sync.js
 *   AI_CONCURRENCY=10 node src/ai/process-events-sync.js
 *
 * Output:
 *   ai/batch_output.jsonl  (same format as OpenAI Batch output)
 */

const fs = require("fs");
const path = require("path");
const https = require("https");
const http = require("http");
const dns = require("dns");

require("./load-env").loadEnv();

if (typeof dns.setDefaultResultOrder === "function") {
  dns.setDefaultResultOrder(process.env.OPENAI_DNS_ORDER || "ipv4first");
}

function baseUrl() {
  return String(
    process.env.OPENAI_BASE_URL || "https://api.openai.com"
  ).replace(/\/+$/, "");
}

function apiKey() {
  return String(process.env.OPENAI_API_KEY || "");
}

function model() {
  return String(process.env.OPENAI_MODEL || "gpt-4o-mini");
}

function ipFamily() {
  const raw = String(process.env.OPENAI_IP_FAMILY || "").trim();
  const n = Number(raw);
  return Number.isFinite(n) && (n === 4 || n === 6) ? n : undefined;
}

function timeoutMs() {
  const raw = Number(process.env.OPENAI_HTTP_TIMEOUT_MS || 120000);
  return Number.isFinite(raw) && raw > 0 ? raw : 120000;
}

function jsonlPath() {
  return path.resolve(
    process.cwd(),
    process.env.AI_JSONL_PATH || "ai/batch_all.jsonl"
  );
}

function outputPath() {
  const dir = path.resolve(process.cwd(), process.env.AI_OUT_DIR || "ai");
  return path.join(dir, "batch_output.jsonl");
}

function concurrency() {
  const raw = Number(process.env.AI_CONCURRENCY || 5);
  return Number.isFinite(raw) && raw > 0 ? Math.floor(raw) : 5;
}

function delayBetweenMs() {
  const raw = Number(process.env.AI_DELAY_BETWEEN_MS || 200);
  return Number.isFinite(raw) && raw >= 0 ? raw : 200;
}

function retryRounds() {
  const raw = Number(process.env.AI_RETRY_ROUNDS || 2);
  return Number.isFinite(raw) && raw >= 0 ? Math.floor(raw) : 2;
}

function httpRequest({ method, url, headers, body }) {
  return new Promise((resolve, reject) => {
    const u = new URL(url);
    const isHttps = u.protocol === "https:";
    const lib = isHttps ? https : http;

    const req = lib.request(
      {
        method,
        hostname: u.hostname,
        port: u.port || (isHttps ? 443 : 80),
        path: u.pathname + u.search,
        headers,
        family: ipFamily(),
      },
      (res) => {
        const chunks = [];
        res.on("data", (c) => chunks.push(c));
        res.on("end", () => {
          const buf = Buffer.concat(chunks);
          resolve({
            status: res.statusCode || 0,
            headers: res.headers,
            body: buf,
          });
        });
      }
    );
    req.on("error", reject);
    req.setTimeout(timeoutMs(), () => {
      const err = new Error(`Request timeout after ${timeoutMs()}ms`);
      err.code = "ETIMEDOUT";
      req.destroy(err);
    });
    if (body) req.write(body);
    req.end();
  });
}

async function delay(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

async function callChatCompletionsWithRetry(requestBody, maxRetries = 3) {
  const url = `${baseUrl()}/v1/chat/completions`;
  const body = Buffer.from(JSON.stringify(requestBody), "utf-8");

  let lastError = null;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const res = await httpRequest({
        method: "POST",
        url,
        headers: {
          Authorization: `Bearer ${apiKey()}`,
          "Content-Type": "application/json",
          "Content-Length": String(body.length),
        },
        body,
      });

      const text = res.body.toString("utf-8");
      let json;
      try {
        json = JSON.parse(text);
      } catch {
        json = { raw: text };
      }
      
      // å¦‚æœæ˜¯ä¸´æ—¶æ€§é”™è¯¯ï¼ˆ429 rate limit, 500+ æœåŠ¡å™¨é”™è¯¯ï¼‰ï¼Œé‡è¯•
      if (res.status === 429 || res.status >= 500) {
        lastError = new Error(`HTTP ${res.status}: ${JSON.stringify(json)}`);
        if (attempt < maxRetries) {
          const waitTime = Math.pow(2, attempt) * 1000; // æŒ‡æ•°é€€é¿
          console.log(`     â³ Retry ${attempt}/${maxRetries} in ${waitTime/1000}s...`);
          await delay(waitTime);
          continue;
        }
      }
      
      return { status: res.status, json };
    } catch (err) {
      lastError = err;
      // ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•
      if (attempt < maxRetries) {
        const waitTime = Math.pow(2, attempt) * 1000;
        console.log(`     â³ Network error, retry ${attempt}/${maxRetries} in ${waitTime/1000}s...`);
        await delay(waitTime);
        continue;
      }
    }
  }
  
  throw lastError || new Error("Unknown error after retries");
}

/**
 * å°† Responses API æ ¼å¼çš„è¯·æ±‚è½¬æ¢ä¸º Chat Completions æ ¼å¼
 */
function convertToCompletionsFormat(batchRequest) {
  const body = batchRequest.body;
  
  // å¦‚æœè¯·æ±‚ä½“ä¸­æœ‰ input å­—æ®µï¼ˆResponses API æ ¼å¼ï¼‰ï¼Œè½¬æ¢ä¸º messages
  const messages = body.input || body.messages;
  
  // æ„å»º Chat Completions è¯·æ±‚
  const completionsBody = {
    model: body.model || model(),
    messages: messages,
    max_tokens: body.max_output_tokens || body.max_tokens || 700,
  };
  
  // å¦‚æœæœ‰ JSON schema è¾“å‡ºæ ¼å¼è¦æ±‚ï¼Œè½¬æ¢ä¸º response_format
  if (body.text && body.text.format && body.text.format.type === "json_schema") {
    completionsBody.response_format = {
      type: "json_object",
    };
  }
  
  return completionsBody;
}

/**
 * å°† Chat Completions å“åº”è½¬æ¢ä¸º Batch API è¾“å‡ºæ ¼å¼
 */
function convertToBatchOutputFormat(customId, response, statusCode) {
  if (statusCode >= 200 && statusCode < 300 && response.choices) {
    return {
      id: `response_${Date.now()}_${customId}`,
      custom_id: customId,
      response: {
        status_code: statusCode,
        body: response,
      },
      error: null,
    };
  } else {
    return {
      id: `response_${Date.now()}_${customId}`,
      custom_id: customId,
      response: null,
      error: {
        code: response.error?.code || "api_error",
        message: response.error?.message || JSON.stringify(response),
      },
    };
  }
}

/**
 * å¹¶å‘æ§åˆ¶å™¨ - é™åˆ¶åŒæ—¶æ‰§è¡Œçš„ Promise æ•°é‡ï¼Œç¡®ä¿ç»“æœæŒ‰ç´¢å¼•é¡ºåº
 */
class ConcurrencyPool {
  constructor(maxConcurrency, delayMs = 200) {
    this.maxConcurrency = maxConcurrency;
    this.delayMs = delayMs;
    this.running = 0;
    this.queue = [];
    this.lastRequestTime = 0;
  }

  /**
   * æ·»åŠ ä»»åŠ¡åˆ°æ± ä¸­ï¼Œè¿”å› Promise
   * @param {Function} task - è¿”å› Promise çš„å‡½æ•°
   * @param {number} index - ä»»åŠ¡çš„åŸå§‹ç´¢å¼•ï¼ˆç”¨äºä¿æŒé¡ºåºï¼‰
   */
  async add(task, index) {
    return new Promise((resolve, reject) => {
      this.queue.push({ task, index, resolve, reject });
      this._tryRun();
    });
  }

  async _tryRun() {
    while (this.running < this.maxConcurrency && this.queue.length > 0) {
      const { task, index, resolve, reject } = this.queue.shift();
      this.running++;

      // ç¡®ä¿è¯·æ±‚é—´éš”
      const now = Date.now();
      const elapsed = now - this.lastRequestTime;
      if (elapsed < this.delayMs) {
        await delay(this.delayMs - elapsed);
      }
      this.lastRequestTime = Date.now();

      // æ‰§è¡Œä»»åŠ¡å¹¶æºå¸¦ç´¢å¼•ä¿¡æ¯
      task()
        .then((result) => resolve({ index, result }))
        .catch((err) => reject({ index, error: err }))
        .finally(() => {
          this.running--;
          this._tryRun();
        });
    }
  }
}

/**
 * å¤„ç†å•ä¸ªè¯·æ±‚
 */
async function processRequest(req, index, total) {
  const customId = req.custom_id;
  const startTime = Date.now();

  try {
    const completionsBody = convertToCompletionsFormat(req);
    const { status, json } = await callChatCompletionsWithRetry(completionsBody);
    const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);

    if (status >= 200 && status < 300) {
      // æå–ç”Ÿæˆçš„å†…å®¹é¢„è§ˆ
      let preview = "";
      if (json.choices && json.choices[0] && json.choices[0].message) {
        const content = json.choices[0].message.content || "";
        preview = content.substring(0, 50).replace(/\n/g, " ");
      }
      console.log(`  âœ… [${index + 1}/${total}] ${customId} (${elapsed}s) ${preview}...`);
      return { success: true, result: convertToBatchOutputFormat(customId, json, status) };
    } else {
      console.log(`  âŒ [${index + 1}/${total}] ${customId} (${elapsed}s) HTTP ${status}`);
      return { success: false, result: convertToBatchOutputFormat(customId, json, status) };
    }
  } catch (err) {
    const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`  âŒ [${index + 1}/${total}] ${customId} (${elapsed}s) ${err.message}`);
    return {
      success: false,
      result: convertToBatchOutputFormat(customId, { error: { message: err.message } }, 500),
    };
  }
}

async function main() {
  if (!apiKey()) {
    console.error("âŒ Missing OPENAI_API_KEY");
    process.exit(1);
  }

  const input = jsonlPath();
  if (!fs.existsSync(input)) {
    console.error(`âŒ Missing JSONL input: ${input}`);
    console.error(
      "   Generate it first: OPENAI_MODEL=gpt-4o-mini node src/ai/generate-batch.js"
    );
    process.exit(1);
  }

  console.log(`ğŸ“‚ Reading: ${input}`);
  const lines = fs
    .readFileSync(input, "utf-8")
    .split("\n")
    .filter((line) => line.trim());

  const requests = lines.map((line) => JSON.parse(line));
  const delayMs = delayBetweenMs();

  const maxConcurrent = concurrency();
  const maxRetryRounds = retryRounds();

  console.log(`ğŸ“Š Found ${requests.length} requests to process`);
  console.log(`ğŸ¤– Using model: ${model()}`);
  console.log(`ğŸŒ API endpoint: ${baseUrl()}/v1/chat/completions`);
  console.log(`âš¡ Concurrency: ${maxConcurrent} (delay: ${delayMs}ms, retry rounds: ${maxRetryRounds})`);
  console.log("");

  const startTime = Date.now();
  
  // ä½¿ç”¨æ•°ç»„æŒ‰ç´¢å¼•å­˜å‚¨ç»“æœï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
  const taskResults = new Array(requests.length).fill(null);
  
  // ç¬¬ä¸€è½®ï¼šå¹¶å‘å¤„ç†æ‰€æœ‰è¯·æ±‚
  console.log("ğŸ“¡ Processing requests...");
  const pool = new ConcurrencyPool(maxConcurrent, delayMs);
  
  const promises = requests.map((req, index) =>
    pool.add(() => processRequest(req, index, requests.length), index)
  );
  
  // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ”¶é›†ç»“æœ
  const settledResults = await Promise.allSettled(promises);
  
  // å°†ç»“æœæŒ‰ç´¢å¼•æ”¾å…¥æ­£ç¡®ä½ç½®
  settledResults.forEach((settled) => {
    if (settled.status === "fulfilled") {
      const { index, result } = settled.value;
      taskResults[index] = result;
    } else {
      // Promise è¢« rejectï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸º processRequest å†…éƒ¨æ•è·äº†é”™è¯¯ï¼‰
      const { index, error } = settled.reason || {};
      if (index !== undefined) {
        taskResults[index] = {
          success: false,
          result: convertToBatchOutputFormat(
            requests[index].custom_id,
            { error: { message: error?.message || "Unknown error" } },
            500
          ),
        };
      }
    }
  });
  
  // ç¬¬äºŒè½®åŠä¹‹åï¼šé‡è¯•å¤±è´¥çš„ä»»åŠ¡
  for (let round = 1; round <= maxRetryRounds; round++) {
    const failedIndices = taskResults
      .map((r, i) => (!r || !r.success ? i : -1))
      .filter((i) => i >= 0);
    
    if (failedIndices.length === 0) {
      console.log(`\nâœ¨ All requests succeeded!`);
      break;
    }
    
    console.log(`\nğŸ”„ Retry round ${round}/${maxRetryRounds}: ${failedIndices.length} failed requests`);
    
    // é‡è¯•å‰ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    const waitTime = Math.pow(2, round) * 1000;
    console.log(`   Waiting ${waitTime / 1000}s before retry...`);
    await delay(waitTime);
    
    const retryPool = new ConcurrencyPool(maxConcurrent, delayMs);
    const retryPromises = failedIndices.map((index) =>
      retryPool.add(() => processRequest(requests[index], index, requests.length), index)
    );
    
    const retryResults = await Promise.allSettled(retryPromises);
    
    retryResults.forEach((settled) => {
      if (settled.status === "fulfilled") {
        const { index, result } = settled.value;
        taskResults[index] = result;
      }
    });
  }

  // æŒ‰åŸå§‹é¡ºåºæå–ç»“æœ
  const finalResults = taskResults.map((r) => r.result);

  // å†™å…¥è¾“å‡ºæ–‡ä»¶
  const output = outputPath();
  const outputContent = finalResults.map((r) => JSON.stringify(r)).join("\n") + "\n";
  fs.writeFileSync(output, outputContent, "utf-8");

  const successCount = taskResults.filter((r) => r.success).length;
  const failCount = taskResults.filter((r) => !r.success).length;
  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);

  console.log("");
  console.log("=".repeat(50));
  console.log(`âœ… Completed: ${successCount} success, ${failCount} failed`);
  console.log(`â±ï¸  Total time: ${elapsed}s (avg: ${(elapsed / requests.length).toFixed(2)}s/req)`);
  console.log(`ğŸ“„ Output saved to: ${output}`);
  console.log("");
  console.log("Next step:");
  console.log("  node src/ai/download-batch-output.js --local");
}

main().catch((err) => {
  console.error(
    "âŒ process-events-sync.js crashed:",
    err && err.message ? err.message : err
  );
  process.exit(1);
});
